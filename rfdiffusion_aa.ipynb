{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJsYHgSER7xN"
      },
      "source": [
        "#**RFdiffusion aa**\n",
        "RFdiffusion aa is a method for structure generation, with or without conditional information (a motif, target etc). It can perform a whole range of protein design challenges as we have outlined in the RFdiffusion [manuscript](https://www.science.org/doi/10.1126/science.adl2528).\n",
        "\n",
        "**<font color=\"red\">NOTE:</font>** This notebook is in development, we are still working on adding all the options from the manuscript above.\n",
        "\n",
        "For **instructions**, see end of Notebook.\n",
        "\n",
        "\n",
        "\n",
        "This is a modified version of Sergey's notebook by Felipe Engelberger, see [original version](https://colab.research.google.com/github/sokrypton/ColabDesign/blob/main/rf/examples/diffusion_ori.ipynb) of this notebook (from 31Mar2023).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ffOpPfUqHXpb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting: Installing aria2 for faster downloads\n",
            "Completed: Installing aria2 for faster downloads\n",
            "Starting: Installing Python dependencies\n",
            "Completed: Installing Python dependencies\n",
            "Downloading parameters and models...\n",
            "Starting: Downloading and extracting parameters\n",
            "Starting: Installing DGL\n",
            "Completed: Installing DGL\n",
            "Starting: Installing SE3 Transformer\n",
            "Completed: Installing SE3 Transformer\n",
            "Starting: Downloading and setting up 'ananas'\n",
            "Completed: Downloading and setting up 'ananas'\n",
            "Environment setup complete.\n"
          ]
        }
      ],
      "source": [
        "#@title COLAB ONLY setup **RFdiffusion All Atom** (~5m)\n",
        "#%%time\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Function to detect if running on Google Colab\n",
        "def is_colab():\n",
        "    return \"COLAB_GPU\" in os.environ\n",
        "\n",
        "# Base directory setup\n",
        "if is_colab():\n",
        "    BASE_DIR = \"/content\"\n",
        "else:\n",
        "    # For local setup, adjust this path as per your local environment\n",
        "    # By default we will assume you are in the devcontainer path\n",
        "    BASE_DIR = \"/workspaces/all_atom_binder_diffusion\"\n",
        "    \n",
        "    # For setups outside the devcontainer, you may need to adjust this path\n",
        "    #BASE_DIR = os.path.expanduser(\"~\")\n",
        "\n",
        "# Adjust paths based on the environment\n",
        "PARAMS_DIR = os.path.join(BASE_DIR, \"params\")\n",
        "RF_DIFFUSION_DIR = os.path.join(BASE_DIR, \"RFdiffusion\")\n",
        "RF_ALL_ATOM_DIR = os.path.join(BASE_DIR, \"rf_diffusion_all_atom\")\n",
        "\n",
        "# Ensure the params directory exists\n",
        "os.makedirs(PARAMS_DIR, exist_ok=True)\n",
        "\n",
        "def run_command(command, progress_message, wait=True):\n",
        "    \"\"\"\n",
        "    Run a system command with a progress message.\n",
        "    If wait is False, the command is executed in the background.\n",
        "    \"\"\"\n",
        "    print(f\"Starting: {progress_message}\")\n",
        "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
        "    if wait:\n",
        "        stdout, stderr = process.communicate()\n",
        "        if process.returncode != 0:\n",
        "            print(f\"Error during {progress_message}: {stderr}\")\n",
        "            raise subprocess.CalledProcessError(process.returncode, command)\n",
        "        print(f\"Completed: {progress_message}\")\n",
        "    return process\n",
        "\n",
        "def setup_environment_colab():\n",
        "    # Install aria2 if not already installed (for faster downloads)\n",
        "    run_command(\"apt-get install -y aria2\", \"Installing aria2 for faster downloads\")\n",
        "\n",
        "    # Install Python dependencies\n",
        "    run_command(\"pip install jedi omegaconf hydra-core icecream pyrsistent pynvml decorator git+https://github.com/sokrypton/ColabDesign.git@v1.1.1 py3Dmol\", \"Installing Python dependencies\")\n",
        "\n",
        "    # If parameters are already downloaded, skip the download process\n",
        "    if not os.path.isfile(os.path.join(PARAMS_DIR, \"done.txt\")):\n",
        "        print(\"Downloading parameters and models...\")\n",
        "        \n",
        "        # Start downloading parameters and models in the background\n",
        "        download_process = run_command(\n",
        "            f\"cd {PARAMS_DIR} && aria2c -q -x 16 https://files.ipd.uw.edu/krypton/schedules.zip && \"\n",
        "            #\"aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar && \"\n",
        "            \"aria2c -q -x 16 http://files.ipd.uw.edu/pub/RF-All-Atom/weights/RFDiffusionAA_paper_weights.pt && \"\n",
        "            \"tar -xf alphafold_params_2022-12-06.tar && touch done.txt\",\n",
        "            \"Downloading and extracting parameters\", wait=False)\n",
        "\n",
        "    # Clone RFdiffusion repository\n",
        "    if not os.path.isdir(RF_DIFFUSION_DIR):\n",
        "        run_command(f\"git clone --branch max https://github.com/engelberger/RFdiffusion.git {RF_DIFFUSION_DIR}\", \"Cloning RFdiffusion repository\")\n",
        "\n",
        "    # Clone RFdiffusion all atom repository\n",
        "    if not os.path.isdir(RF_ALL_ATOM_DIR):\n",
        "        run_command(f\"git clone --recurse-submodules --branch colab_march_2024 https://github.com/engelberger/rf_diffusion_all_atom.git {RF_ALL_ATOM_DIR}\", \"Cloning RFdiffusion all atom repository\")\n",
        "\n",
        "    # Install DGL\n",
        "    run_command(\"pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html\", \"Installing DGL\")\n",
        "\n",
        "    # Install SE3 Transformer\n",
        "    run_command(f\"cd {os.path.join(RF_DIFFUSION_DIR, 'env/SE3Transformer')} && pip install -q --no-cache-dir -r requirements.txt && pip install -q .\", \"Installing SE3 Transformer\")\n",
        "\n",
        "    # Download and set execute permissions for 'ananas'\n",
        "    run_command(f\"wget -qnc https://files.ipd.uw.edu/krypton/ananas -P {BASE_DIR} && chmod +x {os.path.join(BASE_DIR, 'ananas')}\", \"Downloading and setting up 'ananas'\")\n",
        "\n",
        "    # Wait for the download process to complete\n",
        "    download_process.communicate()\n",
        "    print(\"Environment setup complete.\")\n",
        "\n",
        "# Call the setup function\n",
        "setup_environment_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "QZM_Q39_zwN1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output base directory: /root/output/ligand_protein_motif\n",
            "Final output path: /root/output/ligand_protein_motif/sample_0\n",
            "Running command: python ./rf_diffusion_all_atom/run_inference.py --config-name=config --config-dir=/root/output/ligand_protein_motif/sample_0 diffuser.T=50\n",
            "/usr/local/lib/python3.10/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
            "warnings.warn(msg, UserWarning)\n",
            "Error executing job with overrides: ['diffuser.T=50']\n",
            "Traceback (most recent call last):\n",
            "File \"/workspaces/all_atom_binder_diffusion/./rf_diffusion_all_atom/run_inference.py\", line 74, in main\n",
            "sampler = get_sampler(conf)\n",
            "File \"/workspaces/all_atom_binder_diffusion/./rf_diffusion_all_atom/run_inference.py\", line 79, in get_sampler\n",
            "make_deterministic()\n",
            "File \"/workspaces/all_atom_binder_diffusion/./rf_diffusion_all_atom/run_inference.py\", line 58, in make_deterministic\n",
            "warm_up_spherical_harmonics()\n",
            "File \"/workspaces/all_atom_binder_diffusion/./rf_diffusion_all_atom/run_inference.py\", line 50, in warm_up_spherical_harmonics\n",
            "relative_pos = torch.tensor([[1.,1.,1.], [1.,1.,1.]]).to(device).to(torch.float32)\n",
            "RuntimeError: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import random\n",
        "import string\n",
        "import yaml\n",
        "import subprocess\n",
        "\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "\n",
        "# Function to detect if running on Google Colab\n",
        "def is_colab():\n",
        "    return \"COLAB_GPU\" in os.environ\n",
        "\n",
        "# Base directory setup\n",
        "BASE_DIR = \"/content\" if is_colab() else os.path.expanduser(\"~\")\n",
        "INPUT_DIR = os.path.join(BASE_DIR, \"input\")\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, \"output\")\n",
        "\n",
        "# Ensure the input and output directories exist\n",
        "os.makedirs(INPUT_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def download_pdb(pdb_code, output_dir=INPUT_DIR):\n",
        "    \"\"\"\n",
        "    Download a PDB file given a PDB code.\n",
        "    \"\"\"\n",
        "    url = f\"https://files.rcsb.org/download/{pdb_code}.pdb\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        pdb_path = os.path.join(output_dir, f\"{pdb_code}.pdb\")\n",
        "        with open(pdb_path, 'w') as file:\n",
        "            file.write(response.text)\n",
        "        return pdb_path\n",
        "    else:\n",
        "        raise ValueError(f\"Failed to download PDB file for {pdb_code}\")\n",
        "\n",
        "def handle_pdb_input(pdb_input_type, pdb_code=None, output_dir=INPUT_DIR):\n",
        "    \"\"\"\n",
        "    Handle PDB input by either uploading a file or downloading it using a PDB code.\n",
        "    \"\"\"\n",
        "    if pdb_input_type == \"upload\":\n",
        "        if is_colab():\n",
        "            from google.colab import files\n",
        "            uploaded = files.upload()\n",
        "            pdb_filename = next(iter(uploaded))\n",
        "            pdb_path = os.path.join(output_dir, pdb_filename)\n",
        "            with open(pdb_path, 'wb') as file:\n",
        "                file.write(uploaded[pdb_filename])\n",
        "            return pdb_path\n",
        "        else:\n",
        "            raise EnvironmentError(\"File upload is only supported on Google Colab.\")\n",
        "    elif pdb_input_type == \"pdb_code\":\n",
        "        return download_pdb(pdb_code, output_dir)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid PDB input type\")\n",
        "\n",
        "def run_rfdiffusion_all_atom(config, output_subfolder=\"ligand_protein_motif\", output_prefix=\"sample\", show_last_n_lines=5, save_stdout=True):\n",
        "    \"\"\"\n",
        "    Wrapper function to run rfdiffusion all atom with specified options, using a YAML configuration file.\n",
        "    The configuration is passed as a dictionary.\n",
        "    \"\"\"\n",
        "    # Generate a base output directory name without duplicating parts of the path\n",
        "    base_output_path = os.path.join(OUTPUT_DIR, output_subfolder)\n",
        "    print(f\"Output base directory: {base_output_path}\")\n",
        "\n",
        "    # Initialize counter to generate a unique output directory\n",
        "    counter = 0\n",
        "    unique_output_path = f\"{base_output_path}/{output_prefix}_{counter}\"\n",
        "    while os.path.exists(unique_output_path):\n",
        "        counter += 1\n",
        "        unique_output_path = f\"{base_output_path}/{output_prefix}_{counter}\"\n",
        "\n",
        "    final_output_path = unique_output_path\n",
        "    print(f\"Final output path: {final_output_path}\")\n",
        "    # Ensure the final output directory exists\n",
        "    os.makedirs(final_output_path, exist_ok=True)\n",
        "\n",
        "    # Update the output_prefix in the config with the actual output path\n",
        "    config[\"inference\"][\"output_prefix\"] = os.path.join(final_output_path, output_prefix)\n",
        "\n",
        "    # Write the configuration to a YAML file inside the correct output directory\n",
        "    config_filename = \"config.yaml\"  # Configuration file name\n",
        "    config_file_path = os.path.join(final_output_path, config_filename)  # Full path to the configuration file\n",
        "    with open(config_file_path, 'w') as file:\n",
        "        yaml.dump(config, file)\n",
        "\n",
        "    # Correct the command to run the inference script with the YAML config file\n",
        "    cmd = [\n",
        "        \"python\", \"./rf_diffusion_all_atom/run_inference.py\",\n",
        "        f\"--config-name={config_filename[:-5]}\",  # Remove the '.yaml' extension\n",
        "        f\"--config-dir={final_output_path}\",\n",
        "        f\"diffuser.T={config['diffuser']['T']}\" # I do not know why this need to be added again if its already in the config.yaml\n",
        "    ]\n",
        "\n",
        "    # Print the command to the console\n",
        "    print(f\"Running command: {' '.join(cmd)}\")\n",
        "\n",
        "    # Initialize a list to keep track of the output lines\n",
        "    output_lines = []\n",
        "\n",
        "    # Use subprocess.Popen to run the command and capture stdout in real-time\n",
        "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
        "\n",
        "    # Correct the path for the log file to ensure it's saved in the final_output_path\n",
        "    if save_stdout:\n",
        "        log_file_path = os.path.join(final_output_path, \"run_inference.log\")  # Corrected path\n",
        "        log_file = open(log_file_path, \"w\")\n",
        "\n",
        "    # Periodically check for new output\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            output_lines.append(output.strip())\n",
        "            # Save to log file if required\n",
        "            if save_stdout:\n",
        "                log_file.write(output)\n",
        "\n",
        "            # Display the last N lines if required\n",
        "            if show_last_n_lines > 0:\n",
        "                display_lines = output_lines[-show_last_n_lines:]\n",
        "                print(\"\\n\".join(display_lines))\n",
        "\n",
        "        # time.sleep(1)  # Adjust the sleep time as needed\n",
        "\n",
        "    # Ensure the process has finished and close the log file if it was opened\n",
        "    process.poll()\n",
        "    if save_stdout:\n",
        "        log_file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#@title ### Small molecule binder design with protein motif\n",
        "\n",
        "# Interface for specifying PDB input\n",
        "pdb_input_type = \"pdb_code\" #@param [\"upload\", \"pdb_code\", \"manual_path\"]\n",
        "pdb_code = \"7v11\" #@param {type:\"string\"}\n",
        "\n",
        "if pdb_input_type == \"pdb_code\":\n",
        "    input_pdb = handle_pdb_input(pdb_input_type, pdb_code)\n",
        "elif pdb_input_type == \"upload\":\n",
        "    print(\"Please upload your PDB file:\")\n",
        "    # Assuming running in Colab\n",
        "    input_pdb = handle_pdb_input(pdb_input_type)\n",
        "elif pdb_input_type == \"manual_path\":\n",
        "    input_pdb = pdb_code  # Assuming the user has manually specified the path\n",
        "\n",
        "contigs = \"100-100\" #@param {type:\"string\"}\n",
        "contig_length = \"\" #@param {type:\"string\"}\n",
        "ligand = \"OQO\" #@param {type:\"string\"}\n",
        "num_designs = 1 #@param {type:\"integer\"}\n",
        "design_startnum = 0 #@param {type:\"integer\"}\n",
        "output_prefix = \"sample\" #@param {type:\"string\"}\n",
        "output_subfolder = \"ligand_protein_motif\" #@param {type:\"string\"}\n",
        "\n",
        "deterministic = True #@param {type:\"boolean\"}\n",
        "T = 50 #@param {type:\"integer\"}\n",
        "\n",
        "# Split contigs string into list\n",
        "contigs_list = contigs.split(',')\n",
        "\n",
        "# Convert contigs list to string format for YAML\n",
        "contigs_yaml = [f\"{contig}\" for contig in contigs_list]\n",
        "contig_length = contig_length if contig_length else None\n",
        "\n",
        "# Define the configuration dictionary based on the user inputs\n",
        "config = {\n",
        "    \"inference\": {\n",
        "        \"deterministic\": deterministic,\n",
        "        \"input_pdb\": input_pdb,\n",
        "        \"ligand\": ligand,\n",
        "        \"num_designs\": num_designs,\n",
        "        \"design_startnum\": design_startnum,\n",
        "        \"ckpt_path\": \"./params/RFDiffusionAA_paper_weights.pt\",\n",
        "        \"model_runner\": \"NRBStyleSelfCond\"\n",
        "    },\n",
        "    \"diffuser\": {\n",
        "        \"T\": T\n",
        "    },\n",
        "    \"contigmap\": {\n",
        "        \"contigs\": contigs_yaml,\n",
        "        \"length\": contig_length\n",
        "    },\n",
        "    \"model\": {\"freeze_track_motif\": \"True\"},\n",
        "    \"defaults\": [\"aa\"]\n",
        "}\n",
        "\n",
        "# Specify additional options for the run function\n",
        "show_last_n_lines = 1  # Show only the last 1 lines of stdout to avoid cluttering the notebook, above 1 is not working at the moment\n",
        "save_stdout = True  # Save the stdout as a logfile in the output folder\n",
        "\n",
        "# Call the run_rfdiffusion_all_atom function with the specified configuration and options\n",
        "run_rfdiffusion_all_atom(config, output_subfolder=output_subfolder, output_prefix=output_prefix, show_last_n_lines=show_last_n_lines, save_stdout=save_stdout)\n",
        "\n",
        "#@markdown After running the diffusion function, you can zip the last job's output for download:\n",
        "\n",
        "#@markdown Run the following cell to zip and download the last job's output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "WcQD7Mk3en3i"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/root/output/ligand_protein_motif/sample_0/sample_0.pdb'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1608660/3875727236.py\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mplot_pdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m   \u001b[0mplot_pdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_1608660/3875727236.py\u001b[0m in \u001b[0;36mplot_pdb\u001b[0;34m(num)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Load the PDB file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mpdb_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Initialize the 3Dmol.js viewer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/output/ligand_protein_motif/sample_0/sample_0.pdb'"
          ]
        }
      ],
      "source": [
        "#@title Display 3D structure {run: \"auto\"}\n",
        "animate = \"interactive\" #@param [\"none\", \"movie\", \"interactive\"]\n",
        "color = \"chain\" #@param [\"rainbow\", \"chain\", \"plddt\"]\n",
        "denoise = True\n",
        "dpi = 100 #@param [\"100\", \"200\", \"400\"] {type:\"raw\"}\n",
        "\n",
        "from colabdesign.shared.plot import pymol_color_list\n",
        "from colabdesign.rf.utils import get_ca, get_Ls, make_animation\n",
        "from string import ascii_uppercase, ascii_lowercase\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import py3Dmol\n",
        "\n",
        "alphabet_list = list(ascii_uppercase + ascii_lowercase)\n",
        "\n",
        "\n",
        "# Construct the base output directory\n",
        "base_output_dir = os.path.join(OUTPUT_DIR, output_subfolder)\n",
        "\n",
        "def find_latest_output_dir(base_dir, prefix):\n",
        "    \"\"\"Find the latest output directory based on the prefix.\"\"\"\n",
        "    dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(prefix)]\n",
        "    if not dirs:\n",
        "        raise FileNotFoundError(f\"No output directories found with prefix '{prefix}' in '{base_dir}'\")\n",
        "    latest_dir = sorted(dirs, key=lambda x: int(x.split('_')[-1]))[-1]\n",
        "    return os.path.join(base_dir, latest_dir)\n",
        "\n",
        "def plot_pdb(num=0):\n",
        "    # Find the latest output directory\n",
        "    latest_output_dir = find_latest_output_dir(base_output_dir, output_prefix)\n",
        "\n",
        "    # Construct the path to the PDB file\n",
        "    pdb_path = os.path.join(latest_output_dir, f\"{output_prefix}_{num}.pdb\")\n",
        "\n",
        "    # Load the PDB file\n",
        "    pdb_str = open(pdb_path, 'r').read()\n",
        "\n",
        "    # Initialize the 3Dmol.js viewer\n",
        "    view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js')\n",
        "    view.addModel(pdb_str, 'pdb')\n",
        "\n",
        "    # Apply color scheme\n",
        "    if color == \"rainbow\":\n",
        "        view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "    elif color == \"chain\":\n",
        "        # Example: Apply color by chain\n",
        "        for n, chain, c in zip(range(len(contigs)), alphabet_list, pymol_color_list):\n",
        "            view.setStyle({'chain': chain}, {'cartoon': {'color': c}})\n",
        "            # If chain == B the visualization should be atoms\n",
        "            if chain == \"B\":\n",
        "                view.setStyle({'chain': chain}, {'stick': {}})\n",
        "    else:\n",
        "        # Example: Apply a custom color scheme\n",
        "        view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':0.5,'max':0.9}}})\n",
        "\n",
        "    # Zoom to fit and display the viewer\n",
        "    view.zoomTo()\n",
        "    view.show()\n",
        "\n",
        "\n",
        "\n",
        "if num_designs > 1:\n",
        "  output = widgets.Output()\n",
        "  def on_change(change):\n",
        "    if change['name'] == 'value':\n",
        "      with output:\n",
        "        output.clear_output(wait=True)\n",
        "        plot_pdb(change['new'])\n",
        "  dropdown = widgets.Dropdown(\n",
        "      options=[(f'{k}',k) for k in range(num_designs)],\n",
        "      value=0, description='design:',\n",
        "  )\n",
        "  dropdown.observe(on_change)\n",
        "  display(widgets.VBox([dropdown, output]))\n",
        "  with output:\n",
        "    plot_pdb(dropdown.value)\n",
        "else:\n",
        "  plot_pdb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PhJ2xFUqRSt1"
      },
      "outputs": [],
      "source": [
        "#@title Package and download results\n",
        "#@markdown If you are having issues downloading the result archive,\n",
        "#@markdown try disabling your adblocker and run this cell again.\n",
        "#@markdown  If that fails click on the little folder icon to the\n",
        "#@markdown  left, navigate to file: `name.result.zip`,\n",
        "#@markdown  right-click and select \\\"Download\\\"\n",
        "#@markdown (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
        "import shutil\n",
        "\n",
        "def zip_last_job(output_subfolder=output_subfolder, output_prefix=output_prefix, counter):\n",
        "    \"\"\"\n",
        "    Zip the last job's output directory for download.\n",
        "    \"\"\"\n",
        "    output_prefix = output_prefix + \"/\" + output_subfolder + \"_\" + counter\n",
        "    base_output_path = os.path.join(OUTPUT_DIR, output_prefix)\n",
        "    counter = 0\n",
        "    while os.path.exists(f\"{base_output_path}_{counter}\"):\n",
        "        counter += 1\n",
        "    # Adjust counter to get the last existing directory\n",
        "    counter -= 1\n",
        "    if counter >= 0:\n",
        "        output_path = f\"{base_output_path}_{counter}\"\n",
        "        shutil.make_archive(output_path, 'zip', output_path)\n",
        "        return f\"{output_path}.zip\"\n",
        "    else:\n",
        "        print(\"No output directory found.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Assuming you're in a Jupyter notebook cell\n",
        "from google.colab import files\n",
        "\n",
        "# This cell should be run after the diffusion function to zip and download the output\n",
        "zip_path = zip_last_job(output_prefix=output_prefix)\n",
        "\n",
        "if zip_path and is_colab():\n",
        "    from google.colab import files\n",
        "    files.download(zip_path)\n",
        "else:\n",
        "    print(\"Zip file path:\", zip_path)\n",
        "    print(\"Note: Automatic download is only supported in Google Colab.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOj89riBSVk4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
